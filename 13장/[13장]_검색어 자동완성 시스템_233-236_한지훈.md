# 대규모 시스템 설계 검색어 자동 완성

---

기존 트리 구조 알고리즘에서 최악 결과로 전체를 모두 탐색하는 일이 생길 수 있기에 다음과 같은 부분으로 해결하려 한다.

1. 접두어 최대 길이 제한

2. 각 노드에 인기 검색어를 캐시


## 접두어 최대 길이 제한

 - 사용자가 검색창에 긴 검색어를 입력하는 일은 거의 없다. 따라서 검색어 값을 작은 정숫값(p)으로 가정해도 안전하다.

 - 검색어의 최대 길이를 제한할 수 있다면 접두어 노드를 찾는 단계의 시간 복잡도는 O(p)에서 O(작은 상수값) = O(1)로 바뀔 것이다.

## 노드에 인기 검색어 캐시

 - 각 노드에 k개 인기 검색어를 저장해 두면 전체 트라이를 검색하는 일을 방지할 수 있다.

 - 5~10개 정도의 자동완성 제안을 표시하면 충분하므로, k는 작은 값이다. 아래에선 5개의 질의를 캐시한다 가정하도록 하자

 - 각 노드에 질의어를 캐시하면 top5 검색어를 질의하는 시간 복잡도를 엄청나게 낮출 수 있다. 하지만 각 노드에 질의어를 저장할 공간이 많이 필요하게 된다는 단점도 있다. 그러나 빠른 응답속도가 중요할 경우 저장공간을 희생할 가치가 생기므로 트레이트 오프를 잘 고려하자.

![img_13-8.png](image%2Fimg_13-8.png)

 - 위는 개선된 트라이 구조이다. 각 노드에 가장 인기 있는 검색어 다섯 가지를 저장하도록 했고 예를 들어 접두어 be를 나타내는 노드에는 [best: 35, bet: 29, bee: 20, be: 15, beer: 10]의 5개 검색어를 캐시해 두었다.

 - 이 최적화 방법들을 통해 시간 복잡도가 기존 트라이와 어떻게 달라졌는지 확인해보자.

1. 접두어 노드를  찾는 시간 복잡도는 O(1)로 바뀐다.

2. 최고 인기 검색어 5개를 찾는 질의의 시간 복잡도도 O(1)로 바뀐다. 검색 결과가 이미 캐시 되어 있어서다.



 - 각 단계의 시간 복잡도가 O(1)로 바뀐 덕분에 최고 인기 검색어 k개를 찾는 전체 알고리즘의 시간 복잡도는 O(1)로 바뀐다.

## 데이터 수집 서비스


- 지금까지 살펴본 설계안은 사용자가 검색창에 뭔가 타이핑을 할 때마다 실시간으로 데이터를 수정했다. 이 방법은 다음 2가지 문제로 다소 실용적이지 못하다.

1. 매일 수천만 건의 질의가 입력될 텐데 그때마다 트라이를 갱신하면 질의 서비스는 심각히 느려질 것이다.

2. 일단 트라이가 만들어지고 나면 인기 검색어는 그다지 자주 바뀌지 않을 것이다. 그러니 트라이를 자주 갱신할 필요가 없다.

 - 규모 확장이 쉬운 데이터 수집 서비스를 만들려면 데이터가 어디서 오고 어떻게 이용되는지를 살펴야 한다. 트위터(현 X) 같은 실시간 애플리케이션이라면 제안되는 검색어를 항상 신선하게 유지할 필요가 있겠지만 구글 검색 같은 애플리케이션이라면 그렇게 자주 바꿔줄 이유가 없다.

 - 용례가 달라지더라도 데이터 수집 서비스의 토대는 바뀌지 않는다. 트라이를 만드는 데 쓰는 데이터를 보통 데이터 분석 서비스(analytic)나 로깅 서비스로부터 올 것이기 때문이다.

![image_13-9.png](image%2Fimage_13-9.png)

 - 위는 데이터 분석 서비스의 수정된 설계안이다.
각각 살펴보자.

## 데이터 분석 서비스 로그

 - 데이터 분석 서비스 로그에는 검색창에 입력된 질의에 관한 원본 데이터가 보관된다. 새로운 데이터가 추가될 뿐 수정은 이루어지지 않으며 로그 데이터에는 인덱스를 걸지 않는다.

![table_13-3.png](image%2Ftable_13-3.png)

 - 위와 같이 검색어와 시간이 로그로 남아 저장이 필요하다.

## 로그 취합 서버

 - 데이터 분석 서비스로부터 나오는 로그는 보통 그 양이 엄청나고 데이터 형식도 제각각인 경우가 많은데 따라서 이 데이터를 잘 취합해 우리 시스템에 쉽게 소비할 수 있도록 해야 한다.
 - 데이터 취합 방식은 서비스의 용례에 따라 달라진다. 예시로 트위터(현 X)와 같은 실시간 애플리케이션의 경우 결과를 빠르게 보여주는 것이 중요하기 때문에 데이터 취합 주기를 짧게 가져갈 필요가 있다. 
 - 실시간이 아닌 경우 일주일에 한 번 정도 로그를 취합해도 충분할 것이다. 따라서 면접장에서 데이터 취합의 실시간성이 얼나마 중요하니 확인하는 것은 중요하다. 이 설계안에서는 일주일이면 충분하다 생각하기에 일주일로 가정한다.

## 취합된 데이터

![table_13-4.png](image%2Ftable_13-4.png)

 - 위는 매주 취합한 데이터 사례이다. time 필드는 해당 주가 시작한 날짜를 나타낸다. frequency 필드는 해당 질의가 해당 주에 사용된 횟수의 합이다.

## 작업 서버

 - 작업 서버는 주기적으로 비동기적 작업을 실행하는 서버 집합이다. 트라이 자료구조를 만들고 트라이 데이터베이스에 저장한느 역할을 담당한다.

 
## 트라이 캐시

 - 트라이 캐시는 분산 캐시 시스템으로 트라이 데이터를 메모리에 유지해 읽기 연산 성능을 높이는 구실을 한다. 매주 트라이 데이터베이스의 스냅숏을 떠서 갱신한다.

 



