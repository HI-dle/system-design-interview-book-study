# 검색어 자동완성 시스템
## 트라이 데이터베이스
트라이 데이터베이스는 지속성 저장소입니다. 트라이 데이터베이스로 사용할 수 있는 선택지로는 다음의 두 가지가 있습니다.
- 문서 저장소(document store)
- 키-값 저장소

### 문서 저장소(document store)
우리는 새 트라이를 매주 만들 것이므로, 주기적으로 트라이를 직렬화하여 데이터베이스에 저장할 수 있습니다.

몽고디비(MongoDB)처럼 `문서 저장소`를 활용하면 이런 데이터를 편리하게 저장할 수 있습니다.
> 🤔 왜 문서 저장소를 사용하면 편리할까?
> 
> - 트라이는 본질적으로 계층적인 트리 구조라서 문서 저장소의 중첩 JSON 구조와 잘 맞다.
> - 문서 저장소는 객체를 JSON처럼 넣고 꺼낼 수 있어서, 트라이 같은 복잡한 구조도 쉽게 저장/조회가 가능하다.
> - 관계형 DB는 계층적 구조를 표현하려면 테이블을 여러개로 분리해야하므로 까다롭다

### 키-값 저장소
트라이는 아래 로직을 적용하면 `해시 테이블` 형태로 변환이 가능합니다.
- 트라이에 보관된 모든 접두어를 `해시 테이블 키`로 변환
- 각 트라이 노드에 보관된 모든 데이터를 `해시 테이블 값`으로 변환

![image_13-10.png](image%2Fimage_13-10.png)

> 그림을 잘 보시면, '값'에 'bes'는 포함되지 않는 것을 볼 수 있는데, 이는 검색 횟수가 없기 때문인 듯 합니다.

---

## 질의 서비스
개략적 설계안에서 살펴봤던 '질의 서비스'는 데이터베이스를 활용해서 `최고 인기 검색어` 5개를 골라냈습니다.

아래 그림은 해당 설계안의 `비효율성`을 개선한 새 설계안입니다.
> 책에서는 비효율성으로 데이터베이스의 병목 현상을 언급했었습니다.(데이터가 커질수록 SQL을 통한 응답 속도가 낮아지고, 병목 현상이 일어남)
> 
> 따라서, 응답 속도 관점에서 캐시를 적용한 것이 개선점이 될 듯 합니다.

![image_13-11.png](image%2Fimage_13-11.png)

`캐시 미스`가 발생하는 경우 데이터를 데이터베이스에서 가져와서 캐시에 채웁니다. 그래야 다음에 같은 접두어에 대한 질의가 오면 캐시에 보관된 데이터를 사용해 처리할 수 있게됩니다.
> `캐시 미스`는 캐시 서버에 메모리가 부족하거나 캐시 서버에 장애가 있어도 발생할 수 있다고 합니다.

`질의 서비스`는 번개처럼 빨라야합니다. 따라서 책에서는 아래와 같은 최적화 방안에 대해 고민하기를 제안합니다.
- AJAX 요청
- 브라우저 캐싱
- 데이터 샘플링

### AJAX 요청
웹 애플리케이션의 경우 브라우저는 보통 AJAX 요청을 보내어 자동완성된 검색어 목록을 가져옵니다. 
이 방법의 장점은 요청을 보내고 받기 위해 페이지를 새로고침 할 필요가 없다는 점 입니다.

### 브라우저 캐싱
대부분의 애플리케이션의 경우 자동완성 검색어 결과는 짧은 시간 안에 자주 바뀌진 않습니다.

따라서 검색어들을 `브라우저 캐시`에 넣어두면 후속 질의의 결과는 해당 캐시에서 바로 가져갈 수 있게됩니다.
> 구글 검색 엔진이 이러한 캐시 메커니즘을 사용합니다.
> 
> '한지훈'을 검색해보겠습니다.
> ![hanjihoon.png](image%2Fhanjihoon.png)
> 
> 아래는 응답 헤더입니다.
> ![hanjihoonresult.png](image%2Fhanjihoonresult.png)
> `max-age=3600`, 즉 한 시간 동안 캐시해두는 것을 볼 수 있습니다.
>
> `private`는 요청을 보낸 사용자의 캐시에만 보관될 수 있으며, 공용 캐시에 저장되어서는 안 된다는 뜻입니다.

### 브라우저 캐싱은 어떻게 하는 것일까, 프론트쪽에 로직이 들어가야하는걸까?
보통 백엔드에서 `Cache-control`이라는 헤더를 설정해서 응답하면, 브라우저가 캐싱하게 됩니다.

프론트쪽에서도 `Cache-control`헤더를 설정해줄 수 있지만, 설정해줘도 브라우저는 서버와 통신을 해서, 서버의 리소스가 변경되었는 지 확인하는 작업을 수행합니다.
> 브라우저가 매번 서버와 통신하므로, 완전한 캐싱은 아니라고 할 수 있습니다.
> 
> 추가적으로, 프론트와 서버. 모두 `Cache-control` 설정을 한다면, 서버의 Cache-control로 설정이 됩니다.
> 
> 이는 `응답을 캐싱하는 것`이기 때문입니다.

그럼 프론트엔드에서는 무엇을 할 수 있을까요?

바로 `캐시 자체를 하지 않도록 설정`할 수 있습니다.(`no-store, no-cache, max-age=0`)

> (참고) 프론트엔드 또한 `cache api`를 이용하면 캐싱할 수 있다고 합니다.


### 데이터 샘플링(data sampling)
데이터 샘플링(`data sampling`)이란, '전체 모집단으로부터 일부 데이터를 추출하여 분석하는 과정'을 말합니다.

대규모 시스템의 경우, 모든 질의 결과를 로깅하도록 해 놓으면 CPU 자원과 저장공간을 엄청나게 소진하게 됩니다.

데이터 샘플링 기법은 이럴 때 유용한데, 즉, `N개의 요청 가운데 1개만 로깅하도록 하는 것`입니다.
> 전체를 다 보지 않아도, 일부 데이터만으로도, 비슷한 패턴이라면 전체 로그를 볼 때와 비슷하게 추정할 수 있는 것으로 이해했습니다.
---

## 트라이 연산
트라이는 검색어 자동완성 시스템의 핵심 컴포넌트입니다. 지금부터는 `트라이 관련 연산`들이 어떻게 동작하는 지 살펴보겠습니다.

### 트라이 생성
트라이 생성은 작업 서버가 담당하며, 데이터 분석 서비스의 로그나 데이터베이스로부터 취합된 데이터를 이용합니다.

![image_13-9.png](image%2Fimage_13-9.png)

### 트라이 갱신
트라이를 갱신하는 데는 두 가지 방법이 있습니다.
- 매주 한 번 갱신하는 방법: 새로운 트라이를 만든 다음에 기존 트라이를 대체합니다.
- 트라이의 각 노드를 개별적으로 갱신하는 방법

책에서는 아래 방법인, `트라이의 각 노드를 개별적으로 갱신하는 방법`을 채택하지 않았는데, 성능이 좋지 않기 때문이라고 합니다.

이유는 `트라이 노드를 갱신할 때는 상위 노드도 갱신해야하기 때문`입니다.

아래 그림은 예시입니다.

![image_13-13.png](image%2Fimage_13-13.png)
'beer'의 빈도를 30으로 변경한다고 할 때, 상위 노드도 모두 변경해줘야합니다.

> 트라이가 작을 때는 고려해볼만 하다고 합니다.

---

## 데이터 샘플링을 좀 더 자세히..
데이터 샘플링이란 위에서 '전체 모집단으로부터 일부 데이터를 추출하여 분석하는 과정'이라고 말씀드렸습니다.
데이터 샘플링은 `확률적/비확률적 샘플링` 두 가지로 나뉠 수 있습니다.
- 확률적 샘플링
  - 단순 무작위 샘플링(Simple Random)
    - 전체 집합에서 완전히 랜덤하게 일부 추출
  - 체계적 샘플링(Systematic)
    - 매번 n번째 데이터 선택
  - 충화 샘플링(Stratified)
    - 데이터 집단을 비슷한 특성을 가진 여러 개의 계층으로 나누고 `각 게층에서 일부 샘플을 선택`
  - 군집 샘플링(Cluster)
    - 모집단을 여러 군집으로 나눈 후 `일부 군집을 통째로 선택`
- 비확률적 샘플링
  - 편의 샘플링(Convenience)
    - 쉽게 접근 가능한 데이터만 선택(e.g 가장 최근 로그 100개)
  - 판단 샘플링(Judgement)
    - 전문가의 판단에 따라 선택
  - 눈덩이 샘플링(Snowball)
    - 샘플이 또 다른 샘플을 소개하는 방식(소셜 네트워크 분석 등에서 사용)
      - e.g `처음 몇 명의 사람으로 부터 시작`해서 연결된 사람을 따라가며 샘플링

`확률적 샘플링`은 랜덤/통계 기반으로, 대표성이 높다는 특징이 있고, `비확률적 샘플링`은 상황을 기반으로, 대표성이 낮고, 편향 위험이 있습니다. 