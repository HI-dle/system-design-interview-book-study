# 처리율 제한 장치의 설계

---

## 분산 환경에서의 처리율 제한 장치의 구현

- 단일 서버를 지원하는 처리율 제한 장치를 구현하는 것은 어렵지 않다. 하지만 여러 대의 서버와 병렬 스레드를 지원하도록 시스템을 확장 하는 것은 또 다른 문제이다.
  - 경쟁조건 (race condition)
  - 동기화 (synchronization)

 - 경쟁 조건
   - 레디스에서 카운터의 값을 읽는다.
   - counter + 1 값이 임계치를 넘는지 확인한다.
   - 넘지 않는다면 레디스에 보관된 카운터 값을 1 증가 시킨다.

 - 병행성이 심한 환경에서는 아래 그림과 같은 경쟁 조건 이슈가 발생할 수 있다.
![image_4-14.png](image%2Fimage_4-14.png)


- 레디스에 저장된 변수 counter 값이 3이라고 할때, 두 개 요청을 처리하는 스레드가 각각 병렬로 counter 값을 읽었으며 그 둘 가운데 어느 쪽도 아직 변경된 값을 저장하지 않은 상태라 가정하자.
- 둘 다 다른 요청의 처리 상태는 상관하지 않고 counter에 1을 더한 값을 레디스에 기록할 것이다. 변경된 counter 값이 유효하다 믿는다. 하지만 counter의 값은 5가 되어야 한다.

- 경쟁 조건 문제를 해결하는 가장 널리 알려진 해결책은 락(lock)이다.
- 하지만 lock은 시스템 성능을 상당히 저하 시키는 문제가 있다. 위 설계의 경우 락 대신 쓸 수 있는 해결책이 두 가지 있다.
  - 하나는 루아 스크립트(Lua script)이고 하나는 정렬 집합(sorted set)이라 불리는 레디스 자료구조를 사용하는 것이다.
  - 책에서는 8,13 문서 참고하라지만 루아 스크립트와 정렬 집합은 어느정도 알 것이라 생각하므로 패스하겠다.

### 동기화이슈
- 동기화는 분산 환경에서 고려해야 할 또 다른 중요한 요소다. 수백만 사용자를 지원하려면 한 대의 처리율 제한 장치 서버로는 충분하지 않을 수 있다.
- 그러므로 n개의 처리율 제한 장치 서버는 동기화가 필요하다.
![image_4-15.png](image%2Fimage_4-15.png)
- 위 그림에서 첫 요청에서 클라이언트1은 장치 1로 2는 2로 진행이 된다. 오른쪽 그림은 두번째 요청인데 웹 계층은 무상태이므로 이전 진행과 다른 장치로 보낼 수 있게 되고 그럼 정상적인 동작을 하지 못할 수 있다.

### 해결책

- 고정 세션(sticky sesion)을 활용하여 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 하는 것이다.
- 고정 세션을 추천하지는 않는다. 이유는 확장이 가능하지 않고 유연하지 못하기 때문이다.
- 고정 세션보다 나은 해결책은 레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것이다.

![image_4-16.png](image%2Fimage_4-16.png)
 - 처리율을 제한 장치의 주체를 레디스에서 진행 하는 것이다.

## 성능 최적화
1. - 여러 데이터 센터를 지원하는 문제는 처리율 제한 장치에 매우 중요한 문제라는 것을 주의하고 데이터 센터에서 멀리 떨어진 사용자를 지원 하려다보면 지연 시간(atency)이 증가할 수 밖에 없기 때문에 대부분의 클라우드
  서비스 사업자는 세계 곳곳에 에지서버(edgeserver)를 심어놓고 있다.
   - 예시로 2020년 5월 20일 클라우드 플레어(Cloudflare)는 지역적으로 분산된 194 곳의 위치에 에지서버를 설치해 두고있다.
   - 사용자 트래픽을 가장 가까운 에지 서버로 전달해 지연시간을 줄인다.
2. - 제한 처리 장치 간 데이터 동기화시 최종 일관성 모델을 사용하는 것이다.
   - 최종 일관성 모델은 6장에서 자세히 기술한다 합니다.
   - 간단히 최종 일관성 모델은 분산 시스템에서 자주 사용되는 일관성 모델로, 모든 노드가 언젠가는 동일한 상태로 수렴하는 것을 보장하는 모델이다. 즉시 일관성이 맞춰지진 않아도 시간이 지나 일관성이 맞춰지게 하는 것 입니다.

### 모니터링

- 처리율 제한 장치를 설치한 이후에는 효과적으로 동작하고 있는지 보기 위해 데이터를 모을 필요가 있다. 모니터링을 통해서는 아래 2가지를 확인하기 위해서이다.
- 채택된 처리율 제한 알고리즘이 효과적이다.
- 정의한 처리율 제한 규칙이 효과적이다.
- 모니터링 되는 값에 따라 채택된 알고리즘이 효과적으로 트래픽을 처리하는지 구현에 문제가 없는지 확인하는 것이다.


### 마무리
 - 4장에서 사용한 알고리즘으로는 아래와 같다.
   - 토큰버킷
   - 누출버킷
   - 고정윈도카운터
   - 이동윈도로그
   - 이동윈도카운터
 - 알고리즘 이외에도 해당 알고리즘을 구현하는 아키텍처, 분산 환경에서의 처리율 제한 장치, 성능 최적화와 모니터링 등의 주제를 살펴보았다.

 - 이외에 도움이 될 것들
 - 경성(hard)이나 연성(soft) 처리율 제한
   - 경성 처리율 제한: 요청의 개수는 임계치를 절대 넘어설 수 없다.
   - 연성 처리율 제한: 요청 개수는 잠시 동안은 임계치를 넘어설 수 있다.
 - 이번 장에서는 애플리케이션 계층(OSI 네트워크 계층에서의 7번 계층)에서의 처리율 제한 장치를 알아 보았다.
 - 예를 들어,Iptables를 사용하면 IP 주소(IP는 OSI 3번 계층)에러 처리율 제한을 적용하는 것이 가능하다.
 - OSI 계층은 1번 계층은 물리(Physical) 계층, 2번 계층은 데이터 링크(Data Link) 계층, 3번 계층은 네트워크(Network) 계층, 4번 계층은 전송(Transport) 계층, 5번 계층은 세션(Session) 계층, 6번 계층은 표현(Presentation) 계층, 7번 계층은 애플리케이션(Application) 계층이다.

 - 마지막으로 처리율 제한을 회피하는 방법.
 - 클라이언트를 어떻게 설계하는 것이 최선인가?
   - 클라이언트측 캐시를 사용하여 API 호출 횟수를 줄인다.
   - 처리율 제한의 임계치를 이해하고, 짧은 시간 동안 너무 많은 메시지를 보내지 않도록 한다.
   - 예외나 에러를 처리하는 코드를 도입하여 클라이언트가 예외적 상황으로부터 우아하게(gracefully) 복구될 수 있도록 한다.
   - 재시도(retry) 로직을 구현할 때는 충분한 백오프(lack-off) 시간을 둔다.

---

## 질문

- 여기서 IP 계층에 대해서는 IPtables로 처리율 제한이 가능하다 그랬는데 어디에 적용 될 수 있을까요? IP 주소에 대한 부분이니 웹서버일까요? 다른 계층은 어디에 적용하고 어떻게 적용될 수 있을지 궁금해요

## 답변

- IP 계층(OSI 3계층)에서의 처리율 제한은 웹서버에 적용될 수 있고, 그 외의 네트워크 입구 단에서도 적용 가능하다.

| OSI 계층 | 예시 처리 대상       | 적용 위치      | 처리율 제한 도구 예시                     |
| ------ | -------------- | ---------- | -------------------------------- |
| 3계층    | IP 주소          | 방화벽, OS 커널 | `iptables`, AWS 보안 그룹            |
| 4계층    | 포트, TCP 연결 수   | 로드밸런서, 커널  | `iptables`, L4 로드 밸런서            |
| 7계층    | URL, 사용자, 토큰 등 | 웹서버, 앱서버   | Nginx, Spring RateLimiter, Redis |

 - 1, 2, 5 계층은 처리율 제한에서 좀 벗어나 있다.

| 계층  | 이름                    | 역할             | 처리율 제한과 관련 없는 이유                              |
| --- | --------------------- | -------------- | --------------------------------------------- |
| 1계층 | 물리 계층 (Physical)      | 전기/광 신호, 케이블 등 | **하드웨어** 수준. OS나 소프트웨어에서 제어 불가                |
| 2계층 | 데이터 링크 계층 (Data Link) | MAC 주소, 프레임 전달 | **스위치, NIC**에서 처리. MAC 기반 제어는 일반적인 백엔드 환경과 무관 |
| 5계층 | 세션 계층 (Session)       | 세션 설정/유지       | **현대에는 대부분 7계층에서 구현됨 (ex. JWT)**              |

 - 실제 서비스에서는 아래와 같이 서비스 분담이 가능합니다.

| 위치                                  | 처리율 제한 방식         | 주 담당자        |
| ----------------------------------- | ----------------- | ------------ |
| Cloud Load Balancer (e.g., AWS ALB) | IP당 초당 100건       | 인프라 팀        |
| Nginx                               | 경로별 제한, 요청당 응답 지연 | DevOps + 백엔드 |
| Spring API 서버                       | 사용자 ID당 1분에 5건    | 백엔드 개발자      |
| Redis + Lua 스크립트                    | 분산 시스템에서 글로벌 제한   | 백엔드 개발자      |


 ## 질문
 - p.72 성능 최적화

 > 우선, 여러 데이터센터를 지원하는 문제는 처리율 제한 장치에 매우 중요한 문제

 - 라고 하는데, 어떤 연관관계로 이렇게 언급이 된 걸까요? 뒤에 데이터센터에서 멀리 떨어진 사용자를 지원하다 보면 지연시간이 증가할 수 밖에 없기 때문이다 라고 되어있기는 한데 잘 와닿지는 않아서요.

## 답변

 - 하온님이 이슈에 말씀을 잘 해주셨어요! 물리적으로 멀리 떨어진 데이터 센터를 거칠수록 지연율이 늘어나고 이에 따라 지연이 생기며 같은 맥락으로 여러 데이터 센터를 거치면 같은 이유로 지연율이 늘어나게 됩니다. 처리율을 제한하는 장치는 사용자에게 진입을 막는 형식인데 이렇게 지연이 되면 사용자에게 불편한 사용감을 느끼게 할 것이란 생각이 들어요.

