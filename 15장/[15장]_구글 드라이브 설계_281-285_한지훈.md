# 구글 드라이브 설계

---

>개략적 설계안 제시 및 동의 구하기에서 API와 한 대 서버의 제약 극복 부분입니다.

 - 구글 드라이브 설계시 어떤 API를 제공해야 할까?라는 질문에 기본적으로 3가지 API 제공이 필요하다.

 - 파일 업로드 API, 다운로드 API, 파일 갱신 히스토리 제공 API이다.

1. 파일 업로드 API

 - 이 시스템은 2가지 종류의 업로드를 지원한다.

   - 단순 업로드: 파일 클기가 작을 때 사용한다.

   - 이어 올리기 : 파일 사이즈가 크고 네트워크 문제로 업로드가 중단될 가능성이 높다고 생각될 때

 - API 예시는

 - https://api.example.com/files/upload?uploadType=resumable

 - 위와 같은 API를 사용한다면 인자는 uploadType=resumable, data는 업로드할 로컬 파일이 된다.

 - 이어 올리기는 3 단계의 절차로 이루어진다.

   - 이어 올리기 URL을 위한 최초 요청 전송

   - 데이터를 업로드하고 업로드 상태 모니터링

   - 업로드에 장애가 발생하면 발생 시점부터 업로드를 재시작


2. 파일 다운로드 API

 - https://api.example.com/files/download

 - 인자는 path로 다운로드할 파일의 경로를 받는다.

 - 예시
````json
{
	"path": "/hidle/choi/jinyoung_session.txt"
}
````

3. 파일 갱신 히스토리 API

 - https://api.example.com/files/list_revisions

 - 인자로 path는 갱신 히스토리를 가져올 파일의 경로, limit은 히스토리 길이의 최대치이다.

 - 예시
````json
{
  "path": "/hidle/choi/jinyoung_session.txt",
  "limit": 20
}
````

- 지금까지 나열한 모든 API는 사용자 인증을 필요로 하고 HTTPS 프로토콜을 사용해야 한다. SSL을 지원하는 프로토콜을 이용하는 이유는 클라이언트와 백엔드 서버가 주고 받는 데이터를 보호하기 위함이다.


## 한 대 서버의 제약 극복
 - 업로드되는 파일이 많아지다 보면 결국 파일 시스템은 가득 차게 된다.

![image_15-4.png](image%2Fimage_15-4.png)

 - 위 그림은 파일 시스템이 10MB의 여유공간밖에 남지 않은 상태이다. 이렇게 되면 사용자는 더 이상 파일을 올릴 수 없게 되고 긴급히 문제를 해결해야 한다. 가장 먼저 떠오르는 해결책은 데이터 샤딩이며 여러 서버에 나누어 저장하는 것이다.

![image_15-5.png](image%2Fimage_15-5.png)

- 위는 user_id 기준으로 샤딩한 예시이다. 시스템 구성을 변경하고 모니터링하게 되는 상황을 가정한다면, 데이터를 나누어 저장하고 저장 공간을 늘렸기 때문에 안정적으로 움직일 것이다. 하지만 서버에 장애가 발생시 데이터 유실에 대한 고려를 해야한다. 넷플릭스나 에어비엔비 같은 시장 주도 기업들은 저장소로 아마존 S3를 사용하고 S3는 업계 최고 수준의 규모 확장성, 가용성, 보안, 성능을 제공하는 객체 저장소 서비스이다. 

- 만약 우리 서비스에도 S3를 사용한다고 한다면 S3는 다중화를 지원하는데, 같은 지역 안에서 다중화를 할 수 있고 여러 지역에 걸쳐 다중화를 할 수 있다. AWS 서비스 지역(region)은 아마존 AWS가 데이터 센터를 운영하는 지리적 영역이다.

![image_15-6.png](image%2Fimage_15-6.png)

 - 데이터 다중화시 동일 지역 내 다중화와 여러 지역에 걸친 다중화를 진행할 수 있다.

 - 여러 지역에 걸쳐 다중화하게 되면 데이터 손실을 막고 가용성을 최대한 보장할 수 있으므로 여러 지역에 걸친 다중화를 하기로 가정하자.

 - 위 버킷은 S3에서 파일 시스템의 폴더와 같은 것이다. 파일을 S3에 넣고 나니 이제 데이터 손실 걱정은 덜게 되지만 미래에 같은 문제가 발생할 것을 고려해 개선점을 찾아보자.

   - 로드밸런서 : 네트워크 트래픽을 분산하기 위해 로드밸런서를 사용한다. 로드밸런서는 트래픽을 고르게 분산할 수 있을 뿐 아니라, 특정 웹 서버에 장애가 발생하면 자동으로 서버를 우회해준다.

   - 웹서버 : 로드밸런서를 추가하고 나면 더 많은 웹 서버를 손쉽게 추가할 수 있다. 따라서 트래픽 폭증에 쉽게 대응이 가능하다.

   - 메타데이터 데이터베이스 : 데이터베이스를 파일 저장 서버에서 분리해 SPOF를 회피한다. 아울러 다중화 및 샤딩 정책을 적용해 가용성과 규모 확장성 요구사항에 대응한다.

   - 파일 저장소 : S3를 파일 저장소로 사용하고 가용성과 데이터 무손실을 보장하기 위해 두 개 이상의 지역에 데이터를 다중화한다.

![image_15-7.png](image%2Fimage_15-7.png)

 - 이 모든 부분을 개선하고 나면 웹 서버, 메타데이터 데이터베이스, 파일 저장소가 한 대 서버에서 여러 서버로 잘 분리가 될 것이다.


---

### 질문
> p.282 파일 다운로드 api 위
장애 발생시점 부분에서 장애 발생시점이 장애 발생 상태를 둘 것 같다는 생각이 들었는데 상태로 장애를 판단하고 파일을 저장하던 도중 끊긴 부분 부터 이어 받는 것은 어떻게 할 수 있나요??? 다 읽고 나서는 블록 단위로 저장하니까 총 크기 중 저장된 블록을 제외한 나머지 블록을 저장하나? 란 생각이 들었는데 맞을까용?
---

### 답변
 - S3 기준으로 하겠습니다.
 - 1.서버에서 S3 버킷에 멀티파트 업로드를 시작하고, 고유한 업로드 ID를 발급받습니다. 이 업로드 ID는 해당 업로드를 식별하는 데 사용됩니다.
 - 2.파일 분할 및 업로드: 서버는 파일을 여러 작은 부분(파트)으로 나누고, 각 파트에 대해 업로드 ID와 파트 번호를 사용하여 S3에 업로드합니다.
 - 3.업로드 완료 또는 재개: 각 파트 업로드 요청에 대한 응답을 확인하여 모든 파트가 성공적으로 업로드되었는지 확인합니다. 만약 일부 파트 업로드에 실패하면 실패한 파트만 재업로드합니다.
 - 4.멀티파트 업로드 완료: 모든 파트 업로드가 완료되면 서버는 S3에 멀티파트 업로드 완료 요청을 보냅니다. 이때, 업로드 ID와 모든 파트 번호를 함께 전달합니다.
 - 5.최종 객체 생성: S3는 전달받은 정보로 모든 파트를 결합하여 하나의 객체로 저장합니다.
 - 업로드 실패 처리는 멀티파트 업로드 중에 오류가 발생할때 실패한 파트만 재업로드하면 되므로, 전체 파일을 다시 업로드할 필요가 없습니다.

 - Multipart Upload
![multipart.png](image%2Fmultipart.png)
 - 1. 멀티파트 업로드 시작(initiate-upload)을 요청하면 서버는 멀티파트 업로드에 대한 고유 식별자인 Upload ID를 응답합니다. 부분 업로드, 업로드 완료 또는 업로드 중단 요청 시 항상 Upload ID를 포함해야 하기 때문에 클라이언트는 이 값을 잘 저장해야 합니다.
 - 2. PresignedURL 발급 : 업로드를 위한 AWS의 서명된 URL을 발급받는 요청입니다. 멀티파트 시작 요청에서 받은 Upload ID 그리고 PartNumber 값을 함께 요청해야 합니다. PartNumber는 1부터 10,000까지 파트 번호 지정이 필요합니다. AWS에서 파트 번호를 이용하여 업로드하는 객체의 각 부분과 그 위치를 고유하게 식별하기 때문입니다. 파트 번호는 연속적인 시퀀스로 선택할 필요는 없습니다 (예를 들면 1, 5 및 14를 선택해도 됩니다).
   - 만약 이전에 업로드한 부분과 동일한 부분 번호로 새 부분을 업로드할 경우 이전에 업로드한 부분을 덮어쓰게 됩니다.
 - 3. PresignedURL part 업로드 : 발급받은 PresignedURL에 PUT 메소드로 파트의 바이너리를 실어서 요청합니다. 이때 파트의 용량은 클라이언트에서 결정하여 업로드합니다. 
   - 분할된 파트는 5MB~5GB의 크기만 가능합니다. 다만 마지막 파트는 5MB 이하도 괜찮습니다. 만약 업로드할 파일의 크기가 5MB 이하라면 파트 업로드는 한번 수행되어야 합니다. 즉, 첫 번째 파트가 마지막 파트이기도 하다면 위 규칙은 위반되지 않으며 AWS S3는 멀티파트 업로드로 수락하여 객체를 생성하게 됩니다. 파트는 최대 5GB까지 10,000개까지 업로드할 수 있으니 이론상 5TB 크기의 파일까지 업로드할 수 있습니다. 
   - 파트를 업로드 후 받는 응답 헤더에 MD5 Checksum 값인 ETag(Entity Tag)가 포함되어 있습니다. 클라이언트는 각 파트 업로드 시 PartNumber와 ETag 값을 매칭하여 보관해야 합니다. 이후 멀티파트 업로드 완료 요청에 이러한 값을 포함해야 하기 때문입니다.
 - 4. Multipart 업로드 완료 :멀티파트 업로드 완료는 Upoad ID, 각 PartNumber와 매칭되는 ETag 값이 배열로 포함되어야 합니다. 업로드 완료가 수행되어야 AWS S3에서 PartNumber와 ETag를 기준으로 객체를 재조립합니다. 객체가 매우 클 경우 이 프로세스는 몇 분 정도 걸릴 수 있습니다.

 -  위 프로세스로 하여금 중단된 부분의 Upload ID를 보존하고 Upload ID로 이미 업로드된 파트들의 목록을 반환한다.   
 - 누락된 파트 번호를 기준으로 다시 Presigned URL을 발급
 - PUT 요청으로 해당 파트만 재업로드

동일한 PartNumber로 업로드하면 기존 것을 덮어씀
---


### 질문
> p.285 첫 문단 마지막
2개 이상의 지역에 데이터를 다중화 한다는데 이는 하나의 데이터를 각각 다른 지역에 복제해서 같은 데이터가 중복해서 생기는 것이 맞을까요??
---

### 답변
 - 맞습니다. Amazon S3 데이터 복제는 한 버킷의 데이터를 다른 버킷으로 복사하는 기능입니다. 이를 통해 데이터 백업, 재해 복구, 데이터 공유 등의 목적으로 활용할 수 있습니다. 복제는 동일한 AWS 리전 내에서 또는 다른 리전으로 수행할 수 있으며, 단일 대상 버킷 또는 여러 대상 버킷으로 복제할 수 있습니다.
 - 살짝만 과정을 본다면
   - 1.S3 버킷에 S3 복제 규칙 생성
   - 2.대상 S3 버킷 선택
   - 복제를 위한 IAM 역할 선택 또는 생성
   - 대상 S3 스토리지 클래스 선택















