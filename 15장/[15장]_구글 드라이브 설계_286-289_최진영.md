# 구글 드라이브 설계

---

### 동기화 충돌
구글 드라이브 같은 `대형 저장소 시스템`의 경우 때때로 `동기화 충돌`이 발생할 수 있습니다.

바로 `같은 파일을 두 명의 사용자가 동시에 업데이트`하려는 경우입니다.

**이러한 충돌은 어떻게 해결할 수 있을까요?**

여기서는 다음과 전략을 사용할 예정인데, 

**'먼저 처리되는 변경은 성공, 나중에 처리되는 변경은 충돌이 발생한 것으로 표시'** 하는 전략입니다.

![image_15-8.png](image%2Fimage_15-8.png)

그림에서 보이다시피, 사용자 1, 2가 동시에 같은 파일을 갱신하려 했고, 사용자 2에 대해서는 충돌이 발생했습니다.

오류가 발생한 시점에 이 시스템에는 아래와 같이 두 가지 버전이 존재하게 됩니다.
- 서버에 있는 최신 버전
- 사용자 2가 가지고 있는 로컬 사본(copy)

![image_15-9.png](image%2Fimage_15-9.png)

이 상태에서 사용자는 두 파일을 하나로 합칠지 아니면 둘 중 하나를 다른 파일로 대체할지를 결정해야합니다.

### 개략적 설계안

아래 그림은 이번 면접 문제에 대한 개략적 설계안입니다. 지금부터 각각의 컴포넌트에 대해 조금 더 상세히 알아보겠습니다.

![image_15-10.png](image%2Fimage_15-10.png)

**블록 저장소 서버**
- 파일 블록을 클라우드 저장소에 업로드하는 서버
- 블록 수준 저장소(block-level storage)라고도 하며, 클라우드 환경에서 데이터 파일을 저장하는 기술
- 파일을 여러 블록으로 나눠 저장하며, 각 블록에는 고유한 해시값이 할당
  - 해시값은 `메타데이터 데이터베이스`에 저장됨
- 각 블록은 독립적인 객체로 취급되며 클라우드 저장소 시스템(e.g AWS S3)에 보관됨
  - 파일을 재구성하려면 블록들을 원래 순서대로 합쳐야함
  - (예시 설계안의 경우 한 블록은 드롭박스의 사례를 참고하여 최대 4MB로 정함)

**클라우드 저장소**
- 파일은 블록 단위로 나눠져 클라우드 저장소에 보관

**아카이빙 저장소(cold storage)**
- 오랫동안 사용되지 않은 비활성(inactive) 데이터를 저장하기 위한 컴퓨터 시스템

**메타데이터 데이터베이스**
- 사용자, 파일, 블록, 버전 등의 메타데이터 정보를 관리
- 이 데이터베이스에는 오직 메타데이터만 두고, 실제 파일은 클라우드에 보관

**메타데이터 캐시**
- 성능을 높이기 위해 자주 쓰이는 메타데이터는 캐시

**알림 서비스**
- 예시 설계안의 경우, 클라이언트에게 파일의 추가, 편집, 삭제를 알림으로써 파일의 최신 상태를 확인하도록 하는데 사용

**오프라인 백업 큐(offline backup queue)**
- 클라이언트가 접속 중이 아니라서 파일의 최신 상태를 확인할 수 없을 때, 해당 정보를 이 큐에 두어 나중에 클라이언트가 접속했을 때 동기화될 수 있도록 함

이렇게 개략적 설계안을 살펴보았는데, 핵심 컴포넌트 중 어떤 것은 복잡해서 좀 더 자세하게 들여다 볼 필요가 있습니다.

해당 내용은 상세 설계에서 다루고자 합니다.

---

## 상세 설계
> 이번 절에서는 `블록 저장소 서버, 메타데이터 데이터베이스, 업로드 절차, 다운로드 절차, 알림 서비스, 파일 저장소 공간 및 장애 처리 흐름`에 대해 좀 더 자세히 알아봅니다.

### 블록 저장소 서버

정기적으로 갱신되는 큰 파일들은 업데이트마다 전체 파일을 서버로 보내면 네트워크 대역폭을 많이 잡아먹게 됩니다. 

이를 최적화하는 방법으로는 두 가지 정도를 생각해 볼 수 있습니다.
- 델타 동기화(delta sync): `파일이 수정되면 전체 파일 대신 수정이 일어난 블록만 동기화`
- 압축(compression): `블록 단위로 압축`해 두면 데이터 크기를 많이 줄일 수 있습니다. 이 때 압축 알고리즘은 파일 유형에 따라 정합니다.(`e.g 텍스트 파일 = gzip 혹은 bzip2`)

이 시스템에서 `블록 저장소 서버는 파일 업로드에 관계된 힘든 일을 처리`하는 컴포넌트인데, 아래와 같은 일을 하기 때문입니다.
- 클라이언트가 보낸 `파일을 블록 단위로 분할`
- 각 블록을 압축 알고리즘을 통해 `압축`
- 압축된 블록을 암호화
- 전체 파일을 보내는 대신, `수정된 블록만 전송`

![image_15-11.png](image%2Fimage_15-11.png)

아래 그림은 `수정된 블록만 전송`하는 `델타 동기화 전략`이 어떻게 동작하는지를 보여줍니다.

![image_15-12.png](image%2Fimage_15-12.png)

> 그림이 너무 당연해서.. 제가 궁금한 점들을 적어보았습니다.
> 
> 제가 궁금했던 점은 `그래서 변경된 블록인지는 어떻게 알 수 있는데?` 였습니다.
> 
> 앞서 저희는 `메타데이터 데이터베이스`의 역할에 대해 얘기했었고, 메타데이터 중 하나가 `블록에 대한 해시값`이었는데요.
> 
> 따라서 모든 블록에 대해 다시 한 번 해시 함수를 적용해서 `해시값이 달라진 블록만 업데이트`하게 된다고 합니다.

그래서 우리는 블록 저장소에 `델타 동기화 전략`과 `압축 알고리즘`을 도입하여 네트워크 대역폭 사용량을 절감할 수 있게됩니다.

## 질문
> 지훈 한: 편집 시 동기화 문제 해결 방법이 궁금해용
> 
> 답변은 책에서 제공해준 `참고문헌 [4][5]`를 보고 작성하였습니다.

### Differential synchronization algorithm

일단 동기화에 대한 일반적인 3가지 접근 방식은 `Locking, Event passing, 3-way merges`가 있다고 합니다.

`Locking` 같은 경우는 간단하지만, 공유 문서는 한 번에 한 명의 사용자만 편집할 수 있습니다. 따라서 실시간 협업이 허용되지 않습니다.

`Event passing`은 사용자의 모든 편집 동작(입력, 복사/붙여넣기, 드래그 등)을 그래도 네트워크로 전달해 다른 사용자에게 적용하는 방식입니다.

내용은 간단하지만, 모든 이벤트를 포착해야하며, 이벤트 유실이나 네트워크 불안정에 취약하다는 점이 단점입니다. 또한 동기화 이슈를 완전히 해결하지는 못하는 것 같습니다.

`3-way merges`는 "내가 편집한 문서를 서버에 보내면, 서버는 다른 사람이 편집한 내용과 잘 합쳐서 다시 나에게 보내주는 방식"입니다.

이 방식은 아래 세 가지 버전을 비교해서 병합합니다.
- 사용자 1의 버전
- 사용자 2의 버전
- 공통 조상 버전(처음에 같이 가지고 있던 문서)

이 방식은 `타이핑 중에는 다른 사람 편집 내용을 받을 수 없다`러는 단점이 존재합니다. 그래서 결국은 점점 문서가 동기화가 되지 못하고 충돌이 발생하게 된다고 합니다.

그래서 지금부터는 DiffSync에 대해 설명하고자 합니다.

DiffSync의 원리는 다음과 같습니다.
- 클라이언트와 서버 모두 shadow라 불리는 문서의 마지막 동기화 상태를 저장합니다.
- 주기적으로 현재 문서의 상태와 shadow의 변경사항(diff)를 생성하여 클라이언트-서버 간 교환하고 서로의 문서에 적용합니다.
- 위를 반복하면 서로의 문서가 점차 최신 상태로 일치. 즉, 수렴하게 됩니다.

> 서버는 각 클라이언트별로 shadow를 저장한다고 합니다.
> 
> 또한, 서버가 클라이언트의 diff를 받고 자신의 문서를 갱신하게 되는데, 변경사항이 있다면 다른 클라이언트들에게도 diff로 전파한다고 합니다.
> 
> 이 후, 서버의 diff를 받은 클라이언트는 자신의 문서와 shadow에 모두 적용합니다.

그래서 DiffSync의 장점은 아래와 같다고 합니다.
- 간단하면서도 강력한 수렴을 보장한다.
- diff만 보내서 빠르기 때문에 실시간 처리를 최적화합니다.

그럼에도 불구하고, 완벽한 충돌이나 모든 상황에 대응 가능한 것은 아니라고 합니다.

실시간 협업 환경에서는 더 발전된 기술인(`OT, CRDT`)와 같이 쓰거나 보완해서 사용한다고 합니다.

---

위키피디아 피셜, OT(Operation Transformation)은 구글 독스 협업의 핵심 기술로 채택되었다고 합니다(2009년 이긴 하지만..)

OT의 기초만 간단하게 살펴보자면, `편집 연산`을 단위로 사용한다고 합니다.

![image_OT.png](image%2Fimage_OT.png)

예시를 보면, "abc"에 대해 두 클라이언트가 각각 1, 2번 연산을 수행했을 때, 동기화를 해결했다면 결과는 "xab"가 나와야합니다.
그러나 1번을 적용하고 2번을 적용하게 되면, 문자 b가 잘못 삭제되는 경우가 발생합니다.

그래서 OT의 기본 개념은 이전에 실행된 동시 연산에 따라 다음 작업의 매개변수를 조정하여 올바른 결과와 일관성을 유지할 수 있도록 하는 것입니다.

이는 앞 동작이 다음 동작에 영향을 미친다고 할 수 있으며, 연산의 순서에 따라 결과가 달라질 수 있습니다.

---

**CRDT(Conflict-free Replicated Data Types)**

OT와 달리 교환법칙이 설입합니다. 각 동작의 순서와 상관없이 변경 사항만 같으면 같은 상태가 유지됩니다.

OT에서는 각 글자에 인덱스를 부여했기 때문에 문제가 발생했던 것인데, CRDT는 이를 해결하기 위해 각 글자를 유니크한 값으로 간주합니다.

![image_CRDT.png](image%2Fimage_CRDT.png)

따라서 교환 법칙이 성립한다고 합니다.